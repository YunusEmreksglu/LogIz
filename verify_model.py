import pandas as pd
import pickle
import numpy as np
import io

# Model yÃ¼kle
print("ğŸ§  Model yÃ¼kleniyor: ids_model.pkl")
with open('ids_model.pkl', 'rb') as f:
    model = pickle.load(f)

def load_and_clean_csv(filename):
    """CSV dosyasÄ±nÄ± okur ve tÄ±rnak iÅŸaretlerini temizler"""
    with open(filename, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # TÄ±rnaklarÄ± temizle
    lines = content.splitlines()
    cleaned_lines = []
    for line in lines:
        line = line.strip()
        if line.startswith('"') and line.endswith('"'):
            line = line[1:-1]
        cleaned_lines.append(line)
    
    cleaned_content = "\n".join(cleaned_lines)
    return pd.read_csv(io.StringIO(cleaned_content))

def analyze_file(filename):
    print(f"\nğŸ“‚ Analiz ediliyor: {filename}")
    try:
        df = load_and_clean_csv(filename)
        print(f"   SatÄ±r sayÄ±sÄ±: {len(df)}")
        
        # Gereksiz sÃ¼tunlarÄ± at (label varsa)
        X = df.drop(columns=['label', 'attack_cat', 'id'], errors='ignore')
        
        # Kategorik dÃ¶nÃ¼ÅŸÃ¼m (BasitÃ§e, modelde kullanÄ±lan label encoder'lar lazÄ±m ama
        # hÄ±zlÄ± test iÃ§in string'leri 0 yapalÄ±m veya modelin feature_names_in_'e bakalÄ±m)
        # Random Forest genelde sayÄ±sal ister. Model eÄŸitimi sÄ±rasÄ±nda LabelEncoder kullandÄ±k.
        # Burada aynÄ± dÃ¶nÃ¼ÅŸÃ¼mÃ¼ yapmak zorundayÄ±z.
        
        # Basitlik adÄ±na: data.csv zaten sayÄ±sal (data.csv iÃ§eriÄŸine bakÄ±nca kategorik var: tcp, FIN vs)
        # train_model.py iÃ§inde LabelEncoder kullandÄ±k ama kaydetmedik!
        # Bu bÃ¼yÃ¼k bir eksiklik. Model string kabul etmez.
        # train_model.py'de eÄŸitilen LabelEncoder'lar olmadan yeni veri predict edilemez (eÄŸer kategorik ise).
        
        # Ancak user'Ä±n train_model.py'si az Ã¶nce Ã§alÄ±ÅŸtÄ±.
        # O scripti gÃ¼ncelleyip LE'leri de kaydetmesini sÃ¶ylemedim.
        # Bu durumda predict hata verebilir: "could not convert string to float".
        
        # Ã‡Ã–ZÃœM: verify_model.py iÃ§inde train_model.py mantÄ±ÄŸÄ±nÄ± tekrar edip (fit yaparak) transform edemeyiz (farklÄ± mapping olur).
        # Normalde LabelEncoder'Ä± pickle olarak kaydetmek lazÄ±mdÄ±.
        
        # Åimdilik: app.py nasÄ±l yapÄ±yor?
        # app.py her requestte LabelEncoder'Ä± YENÄ°DEN fit ediyor! (Bu yanlÄ±ÅŸ bir yÃ¶ntem ama kod bÃ¶yleydi).
        # app.py:
        # le = LabelEncoder()
        # for col in categorical_cols: data[col] = le.fit_transform(data[col])
        
        # Bu yÃ¶ntemle eÄŸitim ve test verisi farklÄ± ise encoding karÄ±ÅŸÄ±r.
        # Ama app.py bÃ¶yle Ã§alÄ±ÅŸÄ±yorsa ben de burada aynÄ±sÄ±nÄ± yapayÄ±m.
        
        categorical_cols = ["proto", "service", "state", "attack_cat"]
        from sklearn.preprocessing import LabelEncoder
        for col in categorical_cols:
            if col in X.columns:
                le = LabelEncoder()
                X[col] = X[col].astype(str)
                X[col] = le.fit_transform(X[col])
        
        # Eksik feature'larÄ± tamamla (0 ile)
        if hasattr(model, 'feature_names_in_'):
            expected_features = model.feature_names_in_
            missing_features = set(expected_features) - set(X.columns)
            for feat in missing_features:
                X[feat] = 0
            
            # Fazla featurelarÄ± at
            X = X[expected_features]
        
        predictions = model.predict(X)
        
        # SonuÃ§larÄ± Ã¶zetle
        unique, counts = np.unique(predictions, return_counts=True)
        results = dict(zip(unique, counts))
        
        print("   SonuÃ§lar:")
        print(f"   - Normal (0): {results.get(0, 0)}")
        print(f"   - SaldÄ±rÄ± (1): {results.get(1, 0)}")
        
        # DetaylÄ± saldÄ±rÄ± tÃ¼rÃ¼? (Model sadece 0/1 sÄ±nÄ±flandÄ±rma yaptÄ± train_model.py'de)
        
    except Exception as e:
        print(f"   âŒ Hata: {e}")

analyze_file('unsw_sample.csv')
analyze_file('data.csv')
analyze_file('123.csv')
